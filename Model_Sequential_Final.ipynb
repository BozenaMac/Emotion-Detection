{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028bde37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import random\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e6cfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = r\"C:\\Users\\48668\\Documents\\jdszr18-Neuronauci\\Data\\train\"\n",
    "test_path = r\"C:\\Users\\48668\\Documents\\jdszr18-Neuronauci\\Data\\test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1650a249",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (75, 75)\n",
    "batch_size = 32\n",
    "num_classes = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a9696f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,               # Normalize pixel values from [0, 255] to [0, 1]\n",
    "                                    rotation_range=15,            # Randomly rotate images in the range of ±15 degrees\n",
    "                                    width_shift_range=0.1,        # Randomly shift images horizontally by up to 10% of the width\n",
    "                                    height_shift_range=0.1,       # Randomly shift images vertically by up to 10% of the height\n",
    "                                    shear_range=0.1,              # Apply shear transformations (slanting the image)\n",
    "                                    zoom_range=0.1,               # Randomly zoom in/out by up to 10%\n",
    "                                    horizontal_flip=True,         # Randomly flip images horizontally (left-right)\n",
    "                                    fill_mode='nearest'           # Fill in missing pixels after transformation using the nearest pixel values\n",
    "                                    )\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_set = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size, \n",
    "    class_mode='categorical',\n",
    "    shuffle=True, \n",
    "    color_mode='rgb'\n",
    ")\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    color_mode='rgb'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3939bd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Classes: {train_set.class_indices}\")\n",
    "\n",
    "# Reverse the class_indices disctionary (np. 0 -> 'angry', 1 -> 'fear', ...)\n",
    "class_labels = {v: k for k, v in train_set.class_indices.items()}\n",
    "\n",
    "# Exempary images\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.suptitle(\"Przykładowe zdjęcia ze zbioru treningowego:\", fontsize=20)\n",
    "x_batch, y_batch = next(train_set)\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(x_batch[i])\n",
    "    label_index = np.argmax(y_batch[i])\n",
    "    class_name = class_labels[label_index]\n",
    "    plt.title(f\"{class_name}:\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f4313f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding class weights to handle class imbalance\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_set.classes),\n",
    "    y=train_set.classes\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4389ca92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face detection setup\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Function to detect and preprocess faces in images\n",
    "def detect_face(image_path, target_size=(75, 75)):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        return None\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=4)\n",
    "    if len(faces) == 0:\n",
    "        return None\n",
    "    x, y, w, h = faces[0]\n",
    "    face = img[y:y+h, x:x+w]\n",
    "    face_resized = cv2.resize(face, target_size)\n",
    "    return face_resized / 255.0\n",
    "\n",
    "\n",
    "def load_dataset(data_dir, target_size=(75, 75)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    class_names = sorted(os.listdir(data_dir))\n",
    "\n",
    "    for label in class_names:\n",
    "        class_dir = os.path.join(data_dir, label)\n",
    "        for filename in os.listdir(class_dir):\n",
    "            img_path = os.path.join(class_dir, filename)\n",
    "            face = detect_face(img_path, target_size)\n",
    "            if face is not None:\n",
    "                images.append(face)\n",
    "                labels.append(label)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    labels_encoded = le.fit_transform(labels)\n",
    "    one_hot_labels = to_categorical(labels_encoded, num_classes=len(le.classes_))\n",
    "\n",
    "    return np.array(images), one_hot_labels, le\n",
    "\n",
    "X_train, y_train, label_encoder = load_dataset(train_path, target_size)\n",
    "X_val, y_val, _ = load_dataset(test_path, target_size)\n",
    "X_test, y_test, _ = load_dataset(test_path, target_size)\n",
    "\n",
    "\n",
    "print(\"Train data:\", X_train.shape, y_train.shape)\n",
    "print(\"Test data:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ca4750",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    # Blok 1\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', input_shape=(75, 75, 3)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    # Blok 2\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    # Blok 3\n",
    "    layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    # Warstwy gęste\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5b67c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback that changes learning rate when model has stopped improving\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
    "# Early stopping to prevent overfitting\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_set,\n",
    "    steps_per_epoch=len(train_set),\n",
    "    epochs=40,\n",
    "    validation_data=train_set,\n",
    "    validation_steps=len(train_set),\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98bd2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(test_set)\n",
    "print(f\"\\nAccuracy: {acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cc4569",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(accuracy) + 1) # get the number of epochs for X axsis\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(epochs, accuracy, color='blue', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, color='orange', label='Validation accuracy')\n",
    "plt.title('Training vs validation accuracy')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(epochs, loss, color='blue', label='Training loss')\n",
    "plt.plot(epochs, val_loss, color='orange', label='Validation loss')\n",
    "plt.title('Training vs validation loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b32282c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(test_set)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "target_names = [class_labels[i] for i in range(len(class_labels))]\n",
    "print(classification_report(test_set.classes, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b240378e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"emotion_model_final.h5\")\n",
    "print(\"✅ Model was saved as emotion_cnn_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa49d906",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit_per_class = 100\n",
    "\n",
    "def get_limited_dataset(root_dir, target_size=target_size, limit_per_class=limit_per_class):\n",
    "    all_images = []\n",
    "    all_labels = []\n",
    "    class_names = sorted(os.listdir(root_dir))\n",
    "\n",
    "    for label_idx, class_name in enumerate(class_names):\n",
    "        class_dir = os.path.join(root_dir, class_name)\n",
    "        image_files = os.listdir(class_dir)\n",
    "        random.shuffle(image_files)\n",
    "        selected_files = image_files[:limit_per_class]\n",
    "\n",
    "        for image_file in selected_files:\n",
    "            image_path = os.path.join(class_dir, image_file)\n",
    "            img = load_img(image_path, target_size=target_size)\n",
    "            img_array = img_to_array(img) / 255.0\n",
    "            all_images.append(img_array)\n",
    "            all_labels.append(label_idx)\n",
    "\n",
    "    return tf.convert_to_tensor(all_images), tf.convert_to_tensor(all_labels), class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957ff410",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test, class_names = get_limited_dataset(r'C:\\Users\\48668\\Documents\\jdszr18-Neuronauci\\Data\\test', target_size=target_size, limit_per_class=limit_per_class)\n",
    "\n",
    "preds = model.predict(x_test)\n",
    "y_pred = np.argmax(preds, axis=1)\n",
    "y_true = y_test.numpy()\n",
    "\n",
    "print(\"\\n Raport Klasyfikacji:\\n\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "\n",
    "confusion_matrix = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel(\"Predykcja\")\n",
    "plt.ylabel(\"Faktyczna klasa\")\n",
    "plt.title(\"Macierz Pomyłek - Zbiór Testowy\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
